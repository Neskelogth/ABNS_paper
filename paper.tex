\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Proposition of a New Experiment to Better Understand the Relation Between Typicality and Prototypes}



\author{\IEEEauthorblockN{Samuel Kostadinov}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{University of Trento}\\
Trento, Italy \\
samuel.kostadinov@unitn.it}


\maketitle

\begin{abstract}

	

\end{abstract}

\begin{IEEEkeywords}
Typicality, Prototypes, CNNs, Siamese Network
\end{IEEEkeywords}


\section{Introduction}
	
	The typicality of a concept is a topic that needs a lot of exploration, since it's difficult to evaluate precisely the typicality of an object 
	and also because the people's brains are always a little different from each other. The experiment I would like to propose, has the objective of 
	make sure we can understand better the bond between the perceived typicality of an object that belongs to a category and the prototype of that category.
	This can help the scientists to better understand how knowledge is organized in the brain. This experiment consists in different phases, such as
	data collection, feature extraction, prototype construction and similarity judgment.


\section{Background}

	\subsection{Feature extraction}

		Feature extraction is a topic widely studied. 
		This topic has numerous different applications. 
		One of its goals is to reduce the amount of computational power needed for image processing. 
		There are various techniques to extract meaningful features from images. 
		Some of them are very common and very easy to implement. 
		These are, for example, edge extraction or shape analysis. 
		Other possibilities, more advanced, involve neural networks.\\

			\subsubsection{Classic feature extraction techniques}
				
				One of the first feature extraction methods implemented in image processing is edge detection.				
				In 2019, a paper by Owotogbe presented a review of edge detection techniques. 
				These are usually divided into two groups, gradient-based and Gaussian-based. 
				Some examples are the Sobel operator and the Canny edge detector. 
				Each of the methods has pros and cons. 
				It's the user's job to find the most appropriate for its goal~\cite{1}.\\
				
				After edge detection, other techniques began to spread for feature extraction. 
				In a paper by Kumar and Kumar Bhatia written in 2014 \cite{2}, 
				there are some examples of techniques used to extract features. 
				In the first one, the authors present different types of features and then some techniques to extract them. 
				These are:

				\begin{itemize}
				
					\item \textbf{Diagonal based feature extraction techniques}:
					
						In this procedure, the image is divided into zones formed by small squares of pixels. 
						In this case, there would be 19 diagonal lines. 
						The value of each pixel in these diagonals is summed to obtain a single sub feature. 
						Then we can extract a feature by averaging the sub features. 
						With this method, we can extract a feature for every zone. 
						Then by averaging the column-wise and row-wise features we can increase their number. 
						
					
					\item \textbf{Fourier descriptors}:
					
						The Fourier transform is commonly used for shape analysis. 
						The Fourier transformed coefficient form the Fourier descriptors. 
						These descriptors represent the shape in a frequency domain, with the low frequencies symbolizing the general shape and the high frequencies symbolizing details of the shape. 
						Since the transformation usually generates many parameters, only a subset is considered.
					
					
					\item \textbf{Principal Component Analysis (PCA)}:
					
						This procedure is a mathematical way to convert a set of observations into a set of values of uncorrelated variables. 
						These variables are defined so that the first one has the highest variance, and the components are all orthogonal (independent) from each other. 
						
					\item \textbf{Independent component analysis (ICA)}:
					
						ICA is a statistical technique. 
						It aims to use non-Gaussian random variables to represent multidimensional vectors. 
						The random variables should be as independent as possible. 
					
					\item \textbf{Gabor filter}:
					
						A Gabor is a sinusoid multiplied by a Gaussian, and its response is a convolution operation. 
						This type of filter performs well in both spatial and frequency domains. 
					
					\item \textbf{Chain Code Histogram of Character Contour}:
					
						This method is based on a contour following technique. 
						The contour following uses a chain coding standard proposed by Freeman, that assigns a value to every pixel to identify the next pixel in the border.

					\item \textbf{Finding Intersection/Junction in character}:
					
						Using the same standard proposed by Freeman used in Chain Code Histogram, there is the possibility to count intersections (or junctions) and open ends in a figure.					
						
					\item \textbf{Transition feature}:
					
						This method is based on the transition from background to foreground. 
						There are different techniques that can work both on grey level images or in 4-connected or 8-connected images.
					
				\end{itemize}
			
			
			\noindent These were not the only techniques presented in the paper, but since some were more problem-specific (about handwritten character recognition)
			were excluded from the list. These excluded techniques can still be used, but may have worse results or may require some adaptation. 
			The techniques were: Fractal theory techniques, Shadow features of character, Sector approach for feature extraction, 
			Extraction of distance and angle features, Extraction of occupancy and end-point features, and Zernike moments.\\
			In another paper, written in 2013 by Tian \cite{3}, there are some other techniques cited that may result useful:
			
			\begin{itemize}
			
				\item \textbf{Color features}:
					
					Color is one of the most important features humans can perceive. 
					The features we can extract depend on the color space, but once it's defined there are some possibilities. 
					A few examples are color histograms, color moments and color coherence vectors. 
					One of the simple and meaningful, according to the authors, is color moments. 
					The most common color moments are the mean, the standard deviation and the skewness. 
					
				\item \textbf{Texture features}:
				
					Another very important feature of images is texture. 
					Features involving texture analysis can be extracted from groups of pixels. 
					One of the most common methods is a Gabor filter, which can be used by characterizing the central frequency and the orientation parameters.
			
			\end{itemize}
			
		\subsubsection{Deformable shape analysis}
		
			A more sophisticated technique than the ones listed before is shape analysis. Deformable shape analysis, in particular, can be useful to extract features from an image.\\
			In 2005, Felzenszwalb wrote a paper that focuses on representation and detection of deformable shapes~\cite{5}. For the goal of the experiment proposed here, some deformable shape 
			detection techniques can be useful. \\
			The technique proposed strongly relies on the trinagulated polygon representation. This type of representation lets approximate every 2D shape without holes using a representation based on triangles. 
			%The resulting approximation is as precise as the user decides, meaning that it's very flexible for the representation of shapes. 
			%In particular, in the paper the triangulation was done with a technique called constrained Delaunay triangulation (CDT), because of its tight relation with the medial axis transform. 
			The author also make use of the properties of chordal graphs and k-trees.\\
			The technique described in this paper falls under the category of deformable template matching. One of the components of the method is the energy function, a function that associates a cost with every 
			possible transformation. The objective is to find the transformation with the lowest possible cost. This component is very flexible, since depending on the formulation of the energy function the costs 
			can be tuned even for individual triangles. Moreover, it is also possible to integrate learning techniques to learn deformation parameters.
			Since the possible non-rigid transformations of a template are numerous, this kind of techniques usually requires an initialization near to the correct solution, 
			although this is not required for the algorithm presented in this paper. 
			For the implementation of the algorithm itself, a techniques called nonserial dynamic programming was the key factor. In fact, using the order of perfect elimination (property of the every triangulated 
			simple polygon), the algorithm computes the optimal position of every vertex with respect to the other vertices. Once the algorithm solves for the last vertex, it can 
			update all the others as in typical dynamic programming and obtain the optimal location for every vertex.\\
			The learning of the parameters can be seen as looking for the location with the highest. The matching problem is then fed to a statistical framework that computes the configuration minimizing the 
			energy cost, which corresponds to the best template match.
			
			
		\subsubsection{Machine learning based feature extraction techniques}
			
		%\subsubsection{Madical imaging feature extraction techniques}
		
		\subsubsection{Hyperspectral images feature extraction}
			
\section{Data Collection}
\section{Feature Extraction}
\section{Prototype Construction}
\section{Similarity Judgment}


\section{Conclusion}
\section{Possible Further Experiments}

%\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
%bottom of columns. Avoid placing them in the middle of columns. Large 
%figures and tables may span across both columns. Figure captions should be 
%below the figures; table heads should appear above the tables. Insert 
%figures and tables after they are cited in the text. Use the abbreviation 
%``Fig.~\ref{fig}'', even at the beginning of a sentence.

%\begin{table}[htbp]
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\cline{2-4} 
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy& More table copy$^{\mathrm{a}}$& &  \\
%\hline
%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}


%\appendix

%\section{Chordal graphs and k-trees}



\begin{thebibliography}{00}

\bibitem{1} J. S. Owotogbe,T. S. Ibiyemi, and B. A. Adu, ``Edge Detection Techniques on Digital Images - A Review'', International Journal of Innovative Science and Research Technology, vol. 4, issue 11, Nov. 2019
\bibitem{2} Gaurav Kumar, Pradeep Kumar Bhatia, ``A Detailed Review of Feature Extraction in Image Processing Systems'', FourthInternational Conference on Advanced Computing \& Communication Technologies, DOI \url{https://doi.org/10.1109/ACCT.2014.7}, 2014
\bibitem{3} Dong Ping Tian, ``A Review on Image Feature Extraction and Representation Techniques'', International Journal of Multimedia and Ubiquitous Engineering, vol.8, pp. 385-396, July 2013
\bibitem{4} Chiranji Lal Chowdhary, D.P.Acharjya, Segmentation and Feature Extraction in Medical Imaging: A Systematic Review, vol. 167, pp. 26-36, Sep. 2019, doi: \url{https://doi.org/10.1016/j.procs.2020.03.179}
\bibitem{5} Pedro F. Felzenszwalb, ``Representation and Detection of Deformable Shapes'', IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 2, pp. 208-220, Feb. 2005, doi: \url{https://doi.org/10.1109/TPAMI.2005.35} 

\end{thebibliography}
\end{document}